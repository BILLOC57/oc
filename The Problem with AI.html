<div style="font: 16pt Arial, sans-serif; margin: 4%;">
<h1>The Problem with AI</h1>

	<p style="margin: 22pt 6% 0px;">
	The threat AI represents is misinterpreted. The danger is not that some “Super Intelligent” robotic overlord is going to “Out Smart” us someday. It is far more insidious than that. I’ll argue how alarming I see the long-term prospects, before doing so however take a look at a snapshot of the here and now. 
	</p><p style="margin: 22pt 6% 0px;">You will find the nexus @ Dexter Filkins (<a href="https://www.newyorker.com/magazine/2025/07/21/is-the-us-ready-for-the-next-war">article</a>) in the July 14, 2025 issue of ’The New Yorker’. 
	(The tile should be: “War in the first quarter of the 21st Century, a guide”)  He starts in Ukraine w/ drone warfare; segues to Silicon Valley & the Pentagon hooking up; and ends full-on, naming names, w/ the IDF acting on automatically AI “suggested” targeting assessments. The technology is here, and it is already being used in warfare. 
	</p><p style="margin: 22pt 6% 0px;">Romantic fantasy concerns about “Super Intelligence” serve only serve to distract from what is already going on. 
	</p><p style="margin: 22pt 6% 0px;">I use AI for its Large Language Models. To me they are souped up search, handy for the sorts of super arcane technological questions I am want to have. 
	</p><p style="margin: 22pt 6% 0px;">I see what is going on. The logical extension of how I use LLMs is dependence. Once LLMs are accepted as the primary source of knowledge they control Everything. They mediate knowledge. That would be the same as earlier times 
	where the means of communication were mediated by a consensus known as “The Media”.
	</p>

</div>